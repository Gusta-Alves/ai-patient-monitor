# ğŸ¥ Sistema de Monitoramento Inteligente de Pacientes

Sistema completo de IA multimodal para detecÃ§Ã£o de quedas, anÃ¡lise de vÃ­deo e transcriÃ§Ã£o automÃ¡tica, com integraÃ§Ã£o em nuvem AWS via API REST segura.

**Funcionalidades principais:**
- ğŸ¥ DetecÃ§Ã£o de quedas em tempo real com YOLOv8
- ğŸ™ï¸ TranscriÃ§Ã£o de Ã¡udio automÃ¡tica (Google Speech Recognition)
- ğŸ§  AnÃ¡lise multimodal com IA (vÃ­deo + Ã¡udio)
- â˜ï¸ IntegraÃ§Ã£o AWS (S3, SQS, Cognito)
- ğŸ” AutenticaÃ§Ã£o segura via Cognito
- ğŸš€ API REST com FastAPI
- ğŸ³ Suporte a Docker e LocalStack

## ğŸ“‹ Funcionalidades Detalhadas

### 1. DetecÃ§Ã£o de Quedas (`fall_detection.py`)
- **DetecÃ§Ã£o de pessoas** usando YOLOv8 pose estimation
- **MÃ¡quina de estados** para evitar falsos alarmes
- **MÃºltiplos critÃ©rios de anÃ¡lise**:
  - Aspect ratio do corpo (deitado vs em pÃ©)
  - PosiÃ§Ã£o vertical dos keypoints
  - Velocidade de descida
  - AnÃ¡lise da postura corporal
- **Regra de seguranÃ§a**: Se houver mais de uma pessoa na cena, considera seguro (com assistÃªncia)

### 2. TranscriÃ§Ã£o de VÃ­deo (`transcribe_video.py`)
- ExtraÃ§Ã£o de Ã¡udio de arquivos de vÃ­deo
- TranscriÃ§Ã£o automÃ¡tica usando Google Speech Recognition
- Suporte para mÃºltiplos idiomas (configurado para pt-BR)

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Passos

1. Clone o repositÃ³rio:
```bash
git clone <url-do-repositorio>
cd "fase 4 - pos/Aula 4"
```

2. Crie um ambiente virtual:
```bash
python -m venv .venv

# No macOS/Linux:
source .venv/bin/activate

# No Windows:
.venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Baixe o modelo YOLOv8:
O modelo `yolov8n-pose.pt` serÃ¡ baixado automaticamente na primeira execuÃ§Ã£o, ou baixe manualmente de:
https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt

## ğŸŒ VariÃ¡veis de Ambiente

### ConfiguraÃ§Ã£o BÃ¡sica (.env)

Crie um arquivo `.env` na raiz do projeto com as variÃ¡veis necessÃ¡rias:

```bash
# ===== CONFIGURAÃ‡Ã•ES AWS =====
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_DEFAULT_REGION=us-east-1

# ===== CONFIGURAÃ‡Ã•ES SQS =====
QUEUE_URL=FILA-MONITORAMENTO-IDOSOS
# ou use a URL completa se preferir:
# QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789/FILA-MONITORAMENTO-IDOSOS

# ===== CONFIGURAÃ‡Ã•ES S3 =====
# Nome do bucket para armazenar vÃ­deos
BUCKET_NAME=bucket-videos-monitoramento

# ===== AUTENTICAÃ‡ÃƒO COGNITO =====
COGNITO_USER_POOL_ID=us-east-1_xxxxx
COGNITO_CLIENT_ID=abc123def456
COGNITO_CLIENT_SECRET=your_client_secret_here

# ===== DEBUG/DESENVOLVIMENTO =====
USE_LOCALSTACK=false
# Defina como 'true' para usar LocalStack em desenvolvimento local
```

### DescriÃ§Ã£o das VariÃ¡veis

| VariÃ¡vel | ObrigatÃ³rio | PadrÃ£o | DescriÃ§Ã£o |
|----------|-----------|--------|-----------|
| `AWS_ACCESS_KEY_ID` | Sim (produÃ§Ã£o) | - | Chave de acesso AWS |
| `AWS_SECRET_ACCESS_KEY` | Sim (produÃ§Ã£o) | - | Chave secreta AWS |
| `AWS_DEFAULT_REGION` | NÃ£o | `us-east-1` | RegiÃ£o AWS |
| `QUEUE_URL` | NÃ£o | `FILA-MONITORAMENTO-IDOSOS` | URL ou nome da fila SQS |
| `BUCKET_NAME` | NÃ£o | `bucket-videos-monitoramento` | Bucket S3 para vÃ­deos |
| `COGNITO_USER_POOL_ID` | Sim (com API) | - | ID do User Pool Cognito |
| `COGNITO_CLIENT_ID` | Sim (com API) | - | ID da aplicaÃ§Ã£o no Cognito |
| `COGNITO_CLIENT_SECRET` | Sim (com API) | - | Secret da aplicaÃ§Ã£o no Cognito |
| `USE_LOCALSTACK` | NÃ£o | `false` | Usar LocalStack para AWS local |

### Exemplo para Desenvolvimento Local

```bash
# .env para usar LocalStack
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
AWS_DEFAULT_REGION=us-east-1
USE_LOCALSTACK=true
QUEUE_URL=FILA-MONITORAMENTO-IDOSOS
```

### Exemplo para ProduÃ§Ã£o AWS

```bash
# .env para AWS real
AWS_ACCESS_KEY_ID=${seu_access_key}
AWS_SECRET_ACCESS_KEY=${seu_secret_key}
AWS_DEFAULT_REGION=us-east-1
COGNITO_USER_POOL_ID=us-east-1_abc123xyz
COGNITO_CLIENT_ID=def456abc123def456abc123
COGNITO_CLIENT_SECRET=seu_client_secret_altamente_secreto
QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789/FILA-MONITORAMENTO-IDOSOS
BUCKET_NAME=meu-bucket-producao
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ“¦ DependÃªncias

Todas as dependÃªncias estÃ£o em [requirements.txt](requirements.txt). As principais incluem:

| Pacote | Finalidade |
|--------|-----------|
| ultralytics | YOLO para detecÃ§Ã£o de pose |
| opencv-python | Processamento de vÃ­deo |
| fastapi | Framework API REST |
| uvicorn | Servidor ASGI |
| boto3 | IntegraÃ§Ã£o AWS |
| python-jose | ValidaÃ§Ã£o JWT |
| SpeechRecognition | TranscriÃ§Ã£o de Ã¡udio |
| moviepy | ExtraÃ§Ã£o de Ã¡udio |
| openai-whisper | TranscriÃ§Ã£o avanÃ§ada (opcional) |
| transformers | Modelos NLP |
| librosa | Processamento de Ã¡udio |
| python-dotenv | VariÃ¡veis de ambiente |

## ğŸ’» Uso

### OpÃ§Ã£o 1: Scripts Locais (Desenvolvimento RÃ¡pido)

#### DetecÃ§Ã£o de Quedas

1. Coloque seu vÃ­deo como `video.mp4` no diretÃ³rio do projeto
2. Execute o script:
```bash
python processors/fall_detection.py
```

3. Controles durante execuÃ§Ã£o:
   - Pressione `q` para sair
   - O sistema mostrarÃ¡ em tempo real os alertas

**Estados do sistema:**
- ğŸŸ¢ **MONITORANDO: TUDO OK** - Pessoa em pÃ©, movimento normal
- ğŸŸ¡ **ANALISANDO MOVIMENTO...** - PossÃ­vel queda detectada, aguardando confirmaÃ§Ã£o
- ğŸ”´ **ALERTA: QUEDA DETECTADA!** - Queda confirmada, precisa de ajuda
- ğŸŸ¢ **SEGURO: ACOMPANHADO** - Mais de uma pessoa na cena

#### TranscriÃ§Ã£o de VÃ­deo

1. Coloque seu vÃ­deo como `video1.mp4` no diretÃ³rio do projeto
2. Execute o script:
```bash
python processors/transcribe_video.py
```

3. A transcriÃ§Ã£o serÃ¡ salva em `temp_processing/transcription.txt`

**Nota**: Requer conexÃ£o com internet para usar o Google Speech Recognition API.

### OpÃ§Ã£o 2: API REST com FastAPI (Recomendado para ProduÃ§Ã£o)

#### Iniciar o Servidor

```bash
# Ativar ambiente virtual (se ainda nÃ£o estiver)
.venv\Scripts\activate  # Windows
# ou
source .venv/bin/activate  # macOS/Linux

# Iniciar API
python api.py
```

O servidor estarÃ¡ disponÃ­vel em: `http://localhost:8000`

#### DocumentaÃ§Ã£o Interativa da API

ApÃ³s iniciar o servidor, acesse:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

#### Endpoints DisponÃ­veis

##### 1. Health Check
```bash
curl http://localhost:8000/health
```

Resposta:
```json
{"status": "healthy"}
```

##### 2. Login (AutenticaÃ§Ã£o Cognito)
```bash
curl -X POST http://localhost:8000/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "seu_usuario",
    "password": "sua_senha"
  }'
```

Resposta:
```json
{
  "AccessToken": "eyJhbGc...",
  "IdToken": "eyJhbGc...",
  "RefreshToken": "...",
  "ExpiresIn": 3600,
  "TokenType": "Bearer"
}
```

##### 3. Analisar VÃ­deo
```bash
curl -X POST http://localhost:8000/analyze-video \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ID_TOKEN" \
  -d '{
    "video_key": "video.mp4",
    "use_s3": false,
    "use_localstack": false
  }'
```

**ParÃ¢metros:**
- `video_key` (string): Nome do arquivo (local ou no S3)
- `use_s3` (boolean): Se deve tentar baixar do S3
- `use_localstack` (boolean): Se deve usar LocalStack

**Resposta:**
```json
{
  "video_file": "video.mp4",
  "fall_detected": false,
  "confidence_score": 0.95,
  "transcription": "Texto transcrito do Ã¡udio...",
  "sentiment_analysis": {
    "emotion": "neutral",
    "confidence": 0.87
  },
  "alert_sent_to_sqs": false,
  "processing_time_seconds": 45.3
}
```

### OpÃ§Ã£o 3: Docker Compose com LocalStack (Desenvolvimento Completo)

```bash
# Iniciar LocalStack e todos os serviÃ§os
docker-compose -f docker/docker-compose.yml up -d

# Logs em tempo real
docker-compose -f docker/docker-compose.yml logs -f

# Parar tudo
docker-compose -f docker/docker-compose.yml down
```

LocalStack estarÃ¡ disponÃ­vel em: `http://localhost:4566`

Seria necessÃ¡rio tambÃ©m:
- Executar `docker/localstack-init/create_queues.sh` para criar as filas
- Configurar as variÃ¡veis de ambiente com `USE_LOCALSTACK=true`

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Sensibilidade da DetecÃ§Ã£o de Quedas

Edite as constantes em [processors/fall_detection.py](processors/fall_detection.py):

```python
# Frames necessÃ¡rios para confirmar queda
FRAMES_PARA_CONFIRMAR = 5      # Diminua para detectar mais rÃ¡pido

# Frames necessÃ¡rios para resetar apÃ³s queda
FRAMES_PARA_RECUPERAR = 60     # Aumente para evitar resets prematuros

# Limiares de detecÃ§Ã£o YOLOv8
conf=0.6    # ConfianÃ§a mÃ­nima (0.5-0.8 recomendado)
iou=0.4     # IoU para NMS (0.3-0.5 recomendado)

# Limiares de aspecto corporal
MIN_ASPECT_RATIO = 0.5    # Pessoa mais larga que alta = caÃ­da
MAX_ASPECT_RATIO = 0.8    # Pessoa em pÃ© = mais alta que larga
```

### Alterar Idioma da TranscriÃ§Ã£o

Em [processors/transcribe_video.py](processors/transcribe_video.py), edite a linha com `recognize_google`:

```python
text = recognizer.recognize_google(audio, language="pt-BR")
# Idiomas suportados:
# "en-US" (English)
# "es-ES" (EspaÃ±ol)
# "fr-FR" (FranÃ§ais)
# "de-DE" (Deutsch)
# "it-IT" (Italiano)
# "ja-JP" (æ—¥æœ¬èª)
# "zh-CN" (ä¸­æ–‡)
```

### ConfiguraÃ§Ã£o do Whisper (Alternativa ao Google Speech)

Se preferir usar OpenAI Whisper em vez do Google Speech Recognition:

```python
import whisper

model = whisper.load_model("base")  # small, medium, large
result = model.transcribe("audio.wav", language="pt")
text = result["text"]
```

## ğŸ§  Algoritmo Detalhado de DetecÃ§Ã£o de Quedas

O sistema usa uma **mÃ¡quina de estados com 3 estados principais**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NORMAL  â”‚ (Pessoa em pÃ©, monitoramento contÃ­nuo)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ Detecta indicadores de queda
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SUSPEITA â”‚ (Aguardando confirmaÃ§Ã£o, 5 frames)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ Confirmado 5 frames/frames consecutivos?
     â”œâ”€ SIM â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚        â”‚ CAIU   â”‚ (Alerta, 60 frames)
     â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚             â”‚ 60 frames em pÃ©?
     â””â”€ NÃƒO â”€â”€â”€â”€â”€â”€â”€â”˜ Retorna NORMAL
```

### CritÃ©rios de DetecÃ§Ã£o

O sistema analisa mÃºltiplos critÃ©rios:

| CritÃ©rio | Threshold | DescriÃ§Ã£o |
|----------|-----------|-----------|
| Aspect Ratio | > 1.0 | Corpo mais largo que alto |
| Altura Ombros | < 60% frame | Ombros muito baixos |
| Altura Quadril | < 60% frame | Quadril muito baixo |
| Velocidade Descida | > 25 px/frame | Movimento rÃ¡pido para baixo |
| CoincidÃªncia Keypoints | +90% | MÃºltiplos sinais confirmam queda |

## ğŸ“Š Estrutura do Projeto

```
ai-patient-monitor/
â”œâ”€â”€ ğŸ“„ api.py                          # API FastAPI principal
â”œâ”€â”€ ğŸ“„ README.md                       # Este arquivo
â”œâ”€â”€ ğŸ“„ requirements.txt                # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ setup_instructions.md           # InstruÃ§Ãµes detalhadas
â”‚
â”œâ”€â”€ ğŸ“ processors/                     # Processadores de IA
â”‚   â”œâ”€â”€ fall_detection.py              # DetecÃ§Ã£o de quedas com YOLOv8
â”‚   â”œâ”€â”€ transcribe_video.py            # TranscriÃ§Ã£o de Ã¡udio
â”‚   â”œâ”€â”€ analyze_multimodal_ai.py       # AnÃ¡lise multimodal (vÃ­deo+Ã¡udio)
â”‚   â””â”€â”€ text_processor.py              # Processamento de texto
â”‚
â”œâ”€â”€ ğŸ“ orchestrator/                   # OrquestraÃ§Ã£o de pipeline
â”‚   â”œâ”€â”€ cloud_orchestrator.py          # CoordenaÃ§Ã£o do processamento em nuvem
â”‚   â””â”€â”€ mestro.py                      # Maestro para orquestraÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸ“ aws_client/                     # IntegraÃ§Ã£o AWS
â”‚   â””â”€â”€ aws_integration.py             # Cliente SQS, S3
â”‚
â”œâ”€â”€ ğŸ“ config/                         # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ load_envs.py                   # Carregamento de variÃ¡veis de ambiente
â”‚   â””â”€â”€ pipeline_config.py             # ConfiguraÃ§Ã£o do pipeline
â”‚
â”œâ”€â”€ ğŸ“ singletons/                     # PadrÃµes Singleton
â”‚   â””â”€â”€ singletons.py                  # InstÃ¢ncias Ãºnicas
â”‚
â”œâ”€â”€ ğŸ“ docker/                         # Docker & LocalStack
â”‚   â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o de containers
â”‚   â””â”€â”€ localstack-init/               # Scripts de inicializaÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸ“ terraform/                      # Infrastructure as Code (AWS)
â”‚   â”œâ”€â”€ main.tf                        # Recursos S3, SQS
â”‚   â”œâ”€â”€ variables.tf                   # VariÃ¡veis
â”‚   â””â”€â”€ terraform.tfvars               # Valores de entrada
â”‚
â”œâ”€â”€ ğŸ“ temp_processing/                # VÃ­deos e Ã¡udios temporÃ¡rios
â”‚   â””â”€â”€ transcription.txt              # Resultado da transcriÃ§Ã£o
â”‚
â””â”€â”€ ğŸ¤– yolov8n-pose.pt                 # Modelo YOLO (baixado automaticamente)
```

## ğŸ”§ Troubleshooting

### âŒ Problema: "CUDA out of memory"
**SoluÃ§Ã£o**: Use um modelo YOLO menor
```bash
# Em fall_detection.py, altere:
model = YOLO("yolov8n-pose.pt")  # nano
# para:
model = YOLO("yolov8s-pose.pt")  # small
```

### âŒ Problema: "ModuleNotFoundError: No module named 'cv2'"
**SoluÃ§Ã£o**: Reinstale as dependÃªncias
```bash
pip install --upgrade opencv-python
# ou completo:
pip install -r requirements.txt --force-reinstall
```

### âŒ Problema: Google Speech Recognition retorna erro
**SoluÃ§Ã£o**: Verifique conexÃ£o internet ou use Whisper offline
```bash
pip install openai-whisper
# Use whisper em vez de google speech recognition
```

### âŒ Problema: "Token expirado" no Cognito
**SoluÃ§Ã£o**: FaÃ§a login novamente para obter novo token
```bash
# Ou use o RefreshToken para renovar
```

### âŒ Problema: LocalStack nÃ£o conecta
**SoluÃ§Ã£o**: Verifique se estÃ¡ rodando e acessÃ­vel
```bash
curl http://localhost:4566/_localstack/health
# Se falhar, reinicie:
docker-compose -f docker/docker-compose.yml restart
```

## ğŸ“š Recursos Adicionais

- **YOLO DocumentaÃ§Ã£o**: https://docs.ultralytics.com/
- **FastAPI**: https://fastapi.tiangolo.com/
- **AWS Cognito**: https://docs.aws.amazon.com/cognito/
- **LocalStack**: https://docs.localstack.cloud/
- **Terraform AWS**: https://registry.terraform.io/providers/hashicorp/aws/latest

## ğŸ” SeguranÃ§a

### Boas PrÃ¡ticas
1. âœ… Nunca commite `.env` no Git (jÃ¡ estÃ¡ em `.gitignore`)
2. âœ… Use secrets seguros para `COGNITO_CLIENT_SECRET`
3. âœ… Ative HTTPS em produÃ§Ã£o
4. âœ… Rotacionepredere chaves AWS regularmente
5. âœ… Monitore logs do CloudWatch
6. âœ… Use VPC e Security Groups na AWS

### ProteÃ§Ã£o da API
- Token JWT do Cognito obrigatÃ³rio
- ValidaÃ§Ã£o de issuer e audience
- Tokens com expiraÃ§Ã£o (3600s padrÃ£o)
- Refresh tokens para renovaÃ§Ã£o

## ğŸ¤ Contribuindo

1. Crie uma branch: `git checkout -b feature/sua-feature`
2. Commit: `git commit -am 'Add feature'`
3. Push: `git push origin feature/sua-feature`
4. Abra um Pull Request

## ğŸ“ LicenÃ§a

LicenÃ§a MIT - Veja o arquivo LICENSE para detalhes complementares.

## ğŸ› Reportar Problemas

Se encontrou um bug ou tem uma sugestÃ£o de melhoria, abra uma [Issue](../../issues).

## ğŸ“¬ Suporte

Para dÃºvidas ou suporte, entre em contato atravÃ©s de:
- Issues do GitHub
- DocumentaÃ§Ã£o detalhada em [setup_instructions.md](setup_instructions.md)

---

**Desenvolvido com â¤ï¸ para monitoramento inteligente de pacientes**

Ãšltima atualizaÃ§Ã£o: Fevereiro 2026
