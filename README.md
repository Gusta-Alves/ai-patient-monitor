# Sistema de Monitoramento Inteligente

Sistema de detecÃ§Ã£o de quedas e transcriÃ§Ã£o de vÃ­deo usando IA para monitoramento de pacientes.

## ğŸ“‹ Funcionalidades

### 1. DetecÃ§Ã£o de Quedas (`fall_detection.py`)
- **DetecÃ§Ã£o de pessoas** usando YOLOv8 pose estimation
- **MÃ¡quina de estados** para evitar falsos alarmes
- **MÃºltiplos critÃ©rios de anÃ¡lise**:
  - Aspect ratio do corpo (deitado vs em pÃ©)
  - PosiÃ§Ã£o vertical dos keypoints
  - Velocidade de descida
  - AnÃ¡lise da postura corporal
- **Regra de seguranÃ§a**: Se houver mais de uma pessoa na cena, considera seguro (com assistÃªncia)

### 2. TranscriÃ§Ã£o de VÃ­deo (`transcribe_video.py`)
- ExtraÃ§Ã£o de Ã¡udio de arquivos de vÃ­deo
- TranscriÃ§Ã£o automÃ¡tica usando Google Speech Recognition
- Suporte para mÃºltiplos idiomas (configurado para pt-BR)

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Passos

1. Clone o repositÃ³rio:
```bash
git clone <url-do-repositorio>
cd "fase 4 - pos/Aula 4"
```

2. Crie um ambiente virtual:
```bash
python -m venv .venv

# No macOS/Linux:
source .venv/bin/activate

# No Windows:
.venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Baixe o modelo YOLOv8:
O modelo `yolov8n-pose.pt` serÃ¡ baixado automaticamente na primeira execuÃ§Ã£o, ou baixe manualmente de:
https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt

## ğŸ“¦ DependÃªncias

- **ultralytics**: Framework YOLO para detecÃ§Ã£o de objetos e pose estimation
- **opencv-python**: Processamento de imagem e vÃ­deo
- **moviepy**: ManipulaÃ§Ã£o e extraÃ§Ã£o de Ã¡udio de vÃ­deos
- **SpeechRecognition**: TranscriÃ§Ã£o de Ã¡udio para texto

## ğŸ’» Uso

### DetecÃ§Ã£o de Quedas

1. Coloque seu vÃ­deo como `video.mp4` no diretÃ³rio do projeto
2. Execute o script:
```bash
python fall_detection.py
```

3. Controles:
   - Pressione `q` para sair
   - O sistema mostrarÃ¡ em tempo real:
     - Status de monitoramento
     - Alertas de queda
     - Indicador de assistÃªncia (mÃºltiplas pessoas)

**Estados do sistema:**
- ğŸŸ¢ **MONITORANDO: TUDO OK** - Pessoa em pÃ©, movimento normal
- ğŸŸ¡ **ANALISANDO MOVIMENTO...** - PossÃ­vel queda detectada, aguardando confirmaÃ§Ã£o
- ğŸ”´ **ALERTA: QUEDA DETECTADA!** - Queda confirmada, precisa de ajuda
- ğŸŸ¢ **SEGURO: ACOMPANHADO** - Mais de uma pessoa na cena

### TranscriÃ§Ã£o de VÃ­deo

1. Coloque seu vÃ­deo como `video1.mp4` no diretÃ³rio do projeto
2. Execute o script:
```bash
python transcribe_video.py
```

3. A transcriÃ§Ã£o serÃ¡ salva em `transcricao1.txt`

**Nota**: Requer conexÃ£o com internet para usar o Google Speech Recognition API.

## âš™ï¸ ConfiguraÃ§Ã£o

### Ajustar sensibilidade da detecÃ§Ã£o de quedas

Edite as constantes em `fall_detection.py`:

```python
# Frames necessÃ¡rios para confirmar queda
FRAMES_PARA_CONFIRMAR = 5      # Diminua para detectar mais rÃ¡pido

# Frames necessÃ¡rios para resetar apÃ³s queda
FRAMES_PARA_RECUPERAR = 60     # Aumente para evitar resets prematuros

# Limiares de detecÃ§Ã£o
conf=0.6    # ConfianÃ§a mÃ­nima (0.5-0.8 recomendado)
iou=0.4     # IoU para NMS (0.3-0.5 recomendado)
```

### Alterar idioma da transcriÃ§Ã£o

Em `transcribe_video.py`, linha 17:
```python
text = recognizer.recognize_google(audio, language="pt-BR")  # Alterar para "en-US", "es-ES", etc.
```

## ğŸ—ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ fall_detection.py          # Sistema de detecÃ§Ã£o de quedas
â”œâ”€â”€ transcribe_video.py        # Sistema de transcriÃ§Ã£o de vÃ­deo
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ README.md                  # DocumentaÃ§Ã£o
â”œâ”€â”€ .gitignore                # Arquivos ignorados pelo Git
â”œâ”€â”€ yolov8n-pose.pt           # Modelo YOLO (baixar separadamente)
â””â”€â”€ .venv/                    # Ambiente virtual (nÃ£o versionado)
```

## ğŸ¯ Algoritmo de DetecÃ§Ã£o de Quedas

O sistema usa uma **mÃ¡quina de estados com 3 estados**:

1. **NORMAL**: Pessoa em pÃ©, monitoramento contÃ­nuo
2. **SUSPEITA**: Indicadores de queda detectados, aguardando confirmaÃ§Ã£o (5 frames)
3. **CAIU**: Queda confirmada, alerta mantido atÃ© recuperaÃ§Ã£o (60 frames em pÃ©)

**CritÃ©rios de detecÃ§Ã£o:**
- Aspect ratio > 1.0 (corpo mais largo que alto)
- Ombros e quadris na mesma altura vertical
- Velocidade de descida > 25 pixels/frame
- PosiÃ§Ã£o baixa (nariz abaixo de 60% da altura do frame)

## ğŸ“ LicenÃ§a

[Especifique sua licenÃ§a aqui]

## ğŸ‘¥ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:
1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

## ğŸ› Problemas Conhecidos

- A transcriÃ§Ã£o requer conexÃ£o com internet
- VÃ­deos muito longos podem consumir muita memÃ³ria
- O modelo YOLO pode ter falsos positivos em cenÃ¡rios com muita movimentaÃ§Ã£o

## ğŸ“§ Contato

[Adicione suas informaÃ§Ãµes de contato]
