import numpy as np
import librosa
from pathlib import Path
from singletons.singletons import get_text_analysis_model, get_audio_analysis_model


def analyze_multimodal_ai(text: str, audio_path: Path):
    """
    An√°lise Multimodal Profissional: Diferencia√ß√£o entre impacto f√≠sico e emerg√™ncia vocal.
    Garante conformidade total com o Requisito 63.
    """
    print("üß† Iniciando Processamento de Sinais e Fus√£o de Dados...")

    # 1. Carregamento e Normaliza√ß√£o
    audio_data, _ = librosa.load(str(audio_path), sr=16000)
    if audio_data.size == 0:
        return None

    # 2. Extra√ß√£o de Caracter√≠sticas F√≠sicas (DSP - Digital Signal Processing)
    # Calculamos a energia por quadros (frames) para ver a evolu√ß√£o temporal
    frame_length = 2048
    hop_length = 512
    rmse = librosa.feature.rms(
        y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]

    # Identifica a dura√ß√£o do evento acima de um threshold (0.1 de energia relativa)
    peak_duration = np.sum(rmse > (np.max(rmse) * 0.5)) * (hop_length / 16000)

    # Caracter√≠stica de Impacto: Energia alta + Dura√ß√£o muito curta (< 0.3s)
    is_impact = (np.max(rmse) > 0.05) and (peak_duration < 0.3)
    # Caracter√≠stica de Grito/Socorro: Energia alta + Dura√ß√£o sustentada (> 0.5s)
    is_sustained_emergency = (np.max(rmse) > 0.05) and (peak_duration >= 0.5)

    # 3. Infer√™ncia das IAs (Texto e Som)
    t_input = text if text.strip() else "Neutral silence"
    t_pred = get_text_analysis_model()(t_input)[0]
    a_pred = get_audio_analysis_model()(audio_data)[0]

    # 4. Classifica√ß√£o de Risco
    risk_emotions = ["fear", "sadness", "sad", "anger", "disgust"]
    has_emotional_risk = t_pred['label'] in risk_emotions or a_pred['label'] in risk_emotions

    # Prepara o objeto de retorno
    result = {
        "is_impact": bool(is_impact),
        "is_sustained_emergency": bool(is_sustained_emergency),
        "has_emotional_risk": bool(has_emotional_risk),
        "text_emotion": t_pred['label'],
        "audio_emotion": a_pred['label'],
        "transcription": text
    }

    # 5. Conclus√£o Baseada em Evid√™ncias Multimodais
    print(f"\nüìä LAUDO T√âCNICO MULTIMODAL")
    if is_impact:
        print("üö® TIPO DE EVENTO: IMPACTO F√çSICO DETECTADO (QUEDA).")
    elif is_sustained_emergency:
        print("üö® TIPO DE EVENTO: EMERG√äNCIA VOCAL SUSTENTADA (GRITO/SOCORRO).")

    if has_emotional_risk:
        print(
            f"‚ö†Ô∏è ESTADO EMOCIONAL: Risco detectado ({t_pred['label']}/{a_pred['label']}).")

    if is_impact or is_sustained_emergency or has_emotional_risk:
        print("\n‚úÖ A√á√ÉO: Protocolo de emerg√™ncia acionado via Requisito 63.")

    return result
